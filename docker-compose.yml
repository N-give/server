services:
  startup:
    extends:
      file: common.yml
      service: oada-uservice
    image: oada/startup:${OADA_VERSION-build}
    build:
      args:
        OADA_SERVICE: startup
    depends_on:
      - zookeeper
      - kafka
      - arangodb
    expose: # expose only internally, not on host
      - '80'
    environment:
      # set RESETDATABASE to "yes" if you want to drop database on startup and recreate
      - RESETDATABASE=${RESETDATABASE-no}

  auth:
    extends:
      file: common.yml
      service: oada-uservice
    image: oada/auth:${OADA_VERSION-build}
    build:
      args:
        OADA_SERVICE: auth
    depends_on:
      - startup
    networks:
      - http_net
    expose: # expose only internally, not on host
      - '80'

  # http-handler is in charge of maintaining connectiongs to clients and starting
  # the first message for a request into Kafka
  http-handler:
    extends:
      file: common.yml
      service: oada-uservice
    image: oada/http-handler:${OADA_VERSION-build}
    build:
      args:
        OADA_SERVICE: http-handler
    depends_on:
      - startup
    networks:
      - http_net
    expose: # expose only internally, not on host
      - '80' # at one time this mapped 34135 from host to local 80 for some reason
    environment:
      - IGNORE_SCOPE

  sync-handler:
    extends:
      file: common.yml
      service: oada-uservice
    image: oada/sync-handler:${OADA_VERSION-build}
    build:
      args:
        OADA_SERVICE: sync-handler
    depends_on:
      - startup
      - proxy
    networks:
      - http_net
    environment:
      - IGNORE_SCOPE

  write-handler:
    extends:
      file: common.yml
      service: oada-uservice
    image: oada/write-handler:${OADA_VERSION-build}
    build:
      args:
        OADA_SERVICE: write-handler
    depends_on:
      - startup

  users:
    extends:
      file: common.yml
      service: oada-uservice
    image: oada/users:${OADA_VERSION-build}
    build:
      args:
        OADA_SERVICE: users
    depends_on:
      - startup

  rev-graph-update:
    extends:
      file: common.yml
      service: oada-uservice
    image: oada/rev-graph-update:${OADA_VERSION-build}
    build:
      args:
        OADA_SERVICE: rev-graph-update
    depends_on:
      - startup

  well-known:
    extends:
      file: common.yml
      service: oada-uservice
    image: oada/well-known:${OADA_VERSION-build}
    build:
      args:
        OADA_SERVICE: well-known
    depends_on:
      - startup
    networks:
      - http_net
    expose: # expose only internally, not on host
      - '80'

  webhooks:
    extends:
      file: common.yml
      service: oada-uservice
    image: oada/webhooks:${OADA_VERSION-build}
    build:
      args:
        OADA_SERVICE: webhooks
    depends_on:
      - startup
      - proxy
    networks:
      - http_net
    environment:
      - SSL_ALLOW_SELF_SIGNED=1

  permissions-handler:
    extends:
      file: common.yml
      service: oada-uservice
    image: oada/permissions-handler:${OADA_VERSION-build}
    build:
      args:
        OADA_SERVICE: permissions-handler
    depends_on:
      - startup

  shares:
    extends:
      file: common.yml
      service: oada-uservice
    image: oada/shares:${OADA_VERSION-build}
    build:
      args:
        OADA_SERVICE: shares
    depends_on:
      - startup

  # swag with configs for auth, well-known, and http-handler
  proxy:
    build: ./support/proxy
    image: oada/support-proxy:${OADA_VERSION-build}
    cap_add:
      - NET_ADMIN
    networks:
      - http_net
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=America/New_york
      - URL=${DOMAIN:-localhost}
      - SUBDOMAINS=www,
      - VALIDATION=http
      - CERTPROVIDER= #optional
      - DNSPLUGIN= #optional
      - PROPAGATION= #optional
      - DUCKDNSTOKEN= #optional
      - EMAIL= #optional
      - ONLY_SUBDOMAINS=false #optional
      - EXTRA_DOMAINS= #optional
      - STAGING=true #optional (set false for release)
      - MAXMINDDB_LICENSE_KEY= #optional
    volumes:
      # Hack in self-signed ssl for localhost
      - ./support/proxy/selfsigned:/config/keys/letsencrypt:ro
    ports:
      - '${BIND:-0.0.0.0}:${PORT_HTTPS:-443}:443'
      - '${BIND:-0.0.0.0}:${PORT_HTTP:-80}:80'
    restart: unless-stopped

  kafka:
    # Is 2.4 less squirrelly?
    #image: wurstmeister/kafka:2.12-2.4.1
    image: wurstmeister/kafka:2.13-2.7.0
    depends_on:
      - zookeeper
    expose: # expose only internally, not on host
      - '9092'
    restart: unless-stopped
    hostname: kafka
    networks:
      - kafka_net
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 'kafka' # NOTE: this only allows services inside this docker network
      KAFKA_ADVERTISED_PORT: '9092' # to connect to kafka.  Set to machine's IP if you want external.
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_HEAP_OPTS: '-Xmx1g -Xms512M'
      KAFKA_BROKER_ID: 1
      JMX_PORT: 9999
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - kafka_data:/var/lib/kafka

  # Arango is the main backend where core data and graph is stored
  arangodb:
    image: arangodb:3.7.8
    restart: unless-stopped
    networks:
      - arango_net
    volumes:
      - arangodb_data:/var/lib/arangodb3
      - arangodb_apps_data:/var/lib/arangodb3-apps
    expose: # expose only internally, not on host
      - '8529'
    environment:
      # - ARANGO_RANDOM_ROOT_PASSWORD=1
      - ARANGO_NO_AUTH=1
      - ARANGO_STORAGE_ENGINE=rocksdb
      - ARANGO_STATISTICS=0
    #command: ['arangod', '--server.statistics', 'true', '--database.auto-upgrade', 'true']
    command: ['arangod', '--server.statistics', 'true']

  # zookeeper and kafka entries are based on:
  # from https://github.com/wurstmeister/kafka-docker/blob/master/docker-compose.yml
  zookeeper:
    image: wurstmeister/zookeeper
    restart: unless-stopped
    networks:
      - kafka_net
    expose: # expose only internally, not on host
      - '2181'
    volumes:
      - zookeeper_data:/var/lib/zookeeper

volumes:
  arangodb_data:
  arangodb_apps_data:
  kafka_data:
  zookeeper_data:

networks:
  arango_net:
  kafka_net:
  http_net:
  startup_net:

# Set up Mutagen forwards
x-mutagen:
  forward:
    agrango:
      source: 'tcp:localhost:8529'
      destination: 'network://arango_net:tcp:arangodb:8529'
    kafka:
      source: 'tcp:localhost:9092'
      destination: 'network://kafka_net:tcp:kafka:9092'
    zookeeper:
      source: 'tcp:localhost:2181'
      destination: 'network://kafka_net:tcp:zookeeper:2181'
